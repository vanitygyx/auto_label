Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Training/evaluation parameters Namespace(adam_epsilon=1e-08, adv_epsilon=1.0, adv_name='word_embeddings', cache_dir='', config_name='', crf_learning_rate=5e-05, data_dir='datasets\\cluener', device=device(type='cuda'), do_adv=False, do_eval=False, do_lower_case=False, do_predict=True, do_train=False, eval_all_checkpoints=False, eval_max_seq_length=512, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, id2label={0: 'X', 1: 'B-address', 2: 'B-book', 3: 'B-company', 4: 'B-game', 5: 'B-government', 6: 'B-movie', 7: 'B-name', 8: 'B-organization', 9: 'B-position', 10: 'B-scene', 11: 'I-address', 12: 'I-book', 13: 'I-company', 14: 'I-game', 15: 'I-government', 16: 'I-movie', 17: 'I-name', 18: 'I-organization', 19: 'I-position', 20: 'I-scene', 21: 'S-address', 22: 'S-book', 23: 'S-company', 24: 'S-game', 25: 'S-government', 26: 'S-movie', 27: 'S-name', 28: 'S-organization', 29: 'S-position', 30: 'S-scene', 31: 'O', 32: '[START]', 33: '[END]'}, label2id={'X': 0, 'B-address': 1, 'B-book': 2, 'B-company': 3, 'B-game': 4, 'B-government': 5, 'B-movie': 6, 'B-name': 7, 'B-organization': 8, 'B-position': 9, 'B-scene': 10, 'I-address': 11, 'I-book': 12, 'I-company': 13, 'I-game': 14, 'I-government': 15, 'I-movie': 16, 'I-name': 17, 'I-organization': 18, 'I-position': 19, 'I-scene': 20, 'S-address': 21, 'S-book': 22, 'S-company': 23, 'S-game': 24, 'S-government': 25, 'S-movie': 26, 'S-name': 27, 'S-organization': 28, 'S-position': 29, 'S-scene': 30, 'O': 31, '[START]': 32, '[END]': 33}, learning_rate=5e-05, local_rank=-1, logging_steps=200, loss_type='ce', markup='bios', max_grad_norm=1.0, max_steps=-1, model_name_or_path='prev_trained_model\\bert-base-chinese', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='outputs\\output_ours_1108bert', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_train_batch_size=32, predict_checkpoints=0, save_steps=200, seed=42, server_ip='', server_port='', task_name='cluener', tokenizer_name='', train_max_seq_length=128, warmup_proportion=0.1, weight_decay=0.01)
